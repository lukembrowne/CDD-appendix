# Using linear vs. non-linear models

## Introduction

Here, we demonstrate the use of non-linear models, specifically generalized additive models, or GAMs, as implemented in the [mgcv](https://cran.r-project.org/web/packages/mgcv/index.html) R package, to model conspecific density dependence. The primary reason to use non-linear rather than a linear models when estimate density dependence is that if non-linearities are missed, this could introduce potential biases into the results, especially when making comparisons across sites, species, etc.

An advantage of GAMs, which are the primary modeling method used in this appendix, is that they are flexible, relatively easy to work with and to fit to data, and are able to capture both linear and non-linear patterns in the data. However, there is uncertainty about the amount of data needed to properly estimate the model and the number of knots that should be estimated. Also extreme care must be taken when extrapolating beyond the observed data.

Below, we first develop a simulated data set of seedling density dependence where we know the 'truth'\-- aka the parameter values determining the survival and mortality of seedlings within the data set. For the same set of seedlings, we simulate 'linear survival', where survival is a linear function of conspecific density and other random factors (e.g., species, plot, etc.). We also simulate 'nonlinear survival', where survival is a quadratic function of conspecific density and other random factors.

We then fit a series of models: 1) standard generalized linear mixed effects model (GLMER), 2) a GLMER with a quadratic term to capture non-linear effects, and 3) a GAM. We compare the models to the known 'truth' to evaluate which model might perform best under different forms of survival.

## Load packages

```{r message=FALSE, warning=FALSE}

# Load libraries ----------------------------------------------------------

  library(tidyverse)
  library(lubridate)
  library(rstan)
  library(brms)
  library(DHARMa)  # For model diagnostics https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html
  library(mgcv) # For gam models
  library(lme4)
  library(tictoc)
  library(DHARMa.helpers) # remotes::install_github("Pakillo/DHARMa.helpers")
  library(performance)
  library(tidybayes)
  library(modelr)

  
  # Stan options
  options(mc.cores = parallel::detectCores())
  rstan_options(auto_write = FALSE)
  
  
# Set seed for reproducibility --------------------------------------
  
  set.seed(42)  


# Set parallel computing environment --------------------------------------
  library(parallel)
  library(foreach)
  cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
  

```

## Set sample sizes and parameter values

Here, we set the sample sizes and parameter values for the simulated data, determining what is the 'truth'

```{r Setting sample sizes and parameters, message=FALSE}

# Set sample sizes
  max_ind_per_plot <- 40   # Maximum number of individuals of each species per plot
  n_species <- 10 # Number of species in overall data set
  n_census <- 5 # Number of censuses in data set
  n_plots <- 25 # Number of seedling plots nested within each site
  n_sites <- 1 # Number of sites
  
# Set parameter values (response will be on logit scale)
  u_intercept <- 1.8 

# Variances of random effects
  sigma_species     <-  .25
  sigma_census      <-  .25
  sigma_site        <-  .25
  sigma_plot        <-  .25
  sigma_noise       <-  .10 # Residual noise - increasing this adds more noise to the data
  
# Set strength of NDD effects on logit scale  
  beta_NDD <- -1.0 # Community-wide non-linear NDD effects  
  beta_NDD2 <- -0.4 # Quadratic term for non-linear NDD effects
  

```

## Simulate variation in seedling densities across plots

We start with a maximum data set with 'max_ind_per_plot' individuals per species at each plot and then subset this maximal data set later to create variation in densities across plots

```{r Initializing dataset, message=FALSE}

# Create names for species, plots, censuses, and sites  
  spp_names <- paste0("SPP", str_pad(1:n_species, width = 3, pad = 0))
  plot_names <- paste0("P", str_pad(1:n_plots, width = 4, pad = 0))
  census_names <-  paste0("C", str_pad(1:n_census, width = 2, pad = 0))
  site_names <-  paste0("S", str_pad(1:n_sites, width = 2, pad = 0))

# Use expand.grid to start to build out dataset
 dat.sim <-  expand.grid( ind_num = 1:max_ind_per_plot,
                                spp = spp_names,
                                plot = plot_names,
                                site = site_names)
 
# Create unique IDs for each individual 
 dat.sim$id <- paste0("IND", str_pad(1:nrow(dat.sim), width = 5, pad = 0))
 
 
# Expand out censuses so that each individual gets censused n_census times
 dat.sim <- left_join(dat.sim , 
                            expand.grid(id = dat.sim$id,
                                        census = census_names)) %>%
                  dplyr::select(id, everything()) %>%
                  as_tibble()


# Create variation in densities across plots
  # For each species plot combination, sample just a fraction of the seedlings that are there
 
  # Using a beta function for the sampling distribution to weight towards lower density plots
    # Can try out different shapes with this code: 
    # hist(rbeta(1000, shape1 = .25, shape2 = 1.5), breaks = 50)
 
  dat.sim <- dat.sim %>%
    group_by(spp, plot, census, site) %>% # Group by species and plot
    nest() %>% # Turns data into a list-column that can be sampled
    ungroup() %>%
    mutate(fraction_to_keep = rbeta(nrow(.), # Generate what fraction of total maximum # of seedlings to keep at each plot
                                    shape1 = .25, 
                                    shape2 = 1.5)) %>% 
    mutate(samp = map2(data, fraction_to_keep, sample_frac)) %>% # Sampling happens here
    select(-c(data, fraction_to_keep)) %>% # Clean up and unnest
    unnest(samp)


# Create unique IDs for plots nested within sites
 dat.sim$plot <- paste0(dat.sim$site, "-", dat.sim$plot)

 # Add species.census column
 dat.sim$species.census <- paste0(dat.sim$spp, "-", dat.sim$census)
 
 # Take a look at the data set
 dat.sim
 
 # Print out stats about simulated data set

  cat("Final # observations in dataset: ", nrow(dat.sim), " ...
      Final # individuals in dataset: ", length(table(dat.sim$id)), " ...
      Final # species in dataset: ", length(table(dat.sim$spp)), " ...
      Final # plots in dataset: ", length(table(dat.sim$plot)), " ...
      Final # sites in dataset: ", length(table(dat.sim$site)), " ...
      Final # censuses in dataset: ", length(table(dat.sim$census)), " ...")

```

## Calculate conspecific density at each plot

```{r Calculate conspecific density, message=FALSE}
# Calculate conspecific density at each plot and add as 'con_dens' column
dat.sim <- dat.sim %>%
                    group_by(spp, census, plot, site) %>%
                    add_tally() %>% # Counts individuals in plot
                    rename(con_dens = n) %>%
                    mutate(con_dens = con_dens - 1) %>% # Subtract by 1 to remove counting self
                    ungroup()

# Scale con_dens
dat.sim$con_dens_scaled <- scale(dat.sim$con_dens)[, 1]


# Plot histogram of conspecific densities
ggplot(dat.sim, aes(x = con_dens)) +
  geom_histogram(binwidth = 1, color = "black", fill = "steelblue2") +
  labs(x = "Conspecific density", y = "Count", title = "Conspecific densities") + 
  theme_bw(12)

```

## Plot effect of NCDD on survival

The red line shows survival plotted as a linear function of conspecific density, while the blue line shows survival as a non-linear, quadratic function of conspecific density.

```{r Simulate effect of internannual variation in NDD on survival}


# Simulate overall NDD response averaged across all species
  dat.sim$NDD.effect <- beta_NDD
  dat.sim$NDD2.effect <- beta_NDD2 # Quadratic term for non-linear effects


# Plot community-wide effect of NDD on survival
  p = ggplot(dat.sim, aes(x = con_dens_scaled, y = con_dens_scaled * NDD.effect + con_dens_scaled^2 * NDD2.effect)) + 
      geom_line(col = "steelblue2", lwd = 2) +
      geom_line(aes(x = con_dens_scaled, y = con_dens_scaled * NDD.effect), col = "red", lwd = 2) +
      labs(x = "Conspecific density (scaled)", y = "Marginal effect on survival (logit scale)", title = "Effect of NDD on survival") +
      theme_bw()
  
  p
  
```

## Simulating random intercepts

Here, we simulate random effects for species, census, plots, and sites

```{r Simulating species-level intercepts, message=FALSE}
 # Generate species intercepts 
  dat.sim <- dat.sim %>% 
    distinct(spp) %>% 
    mutate(spp.effect = rnorm(nrow(.), mean = 0, sd = 1)) %>%
    mutate(spp.effect = (spp.effect - mean(spp.effect)) / 
             (( 1 / sigma_species) * sd(spp.effect))) %>% # Rescale to get actual simulated sigma
    left_join(., dat.sim)

# Generate census effects
    dat.sim <- dat.sim %>% 
      distinct(census) %>% 
      mutate(census.effect = rnorm(nrow(.), mean = 0, sd = 1)) %>%
      mutate(census.effect = (census.effect - mean(census.effect)) / 
                             (( 1 / sigma_census) * sd(census.effect))) %>% # Rescale to get actual simulated sigma
      left_join(., dat.sim)
 
# Generate plot effects
  dat.sim <- dat.sim %>% 
    distinct(plot) %>% 
    mutate(plot.effect = rnorm(nrow(.), mean = 0, sd = 1)) %>%
    mutate(plot.effect = (plot.effect - mean(plot.effect)) / 
             (( 1 / sigma_plot) * sd(plot.effect))) %>% # Rescale to get actual simulated sigma
    left_join(., dat.sim)
  

# Generate site effects
  dat.sim <- dat.sim %>% 
    distinct(site) %>% 
    mutate(site.effect = rnorm(nrow(.), mean = 0, sd = 1)) %>%
    mutate(site.effect = (site.effect - mean(site.effect)) / 
             (( 1 / sigma_site) * sd(site.effect))) %>% # Rescale to get actual simulated sigma
    left_join(., dat.sim)

# If simulating only 1 site, set this effect to 0
if(n_sites == 1){
  dat.sim$site.effect <- 0
} 
```

## Simulate residual noise

We add some residual noise to the data to simulate the fact that it is very unlikely that we have perfect knowledge of all the factors generating our response variable in a real data set.

```{r Simulate residual noise}
  dat.sim$noise <- rnorm(nrow(dat.sim), mean = 0, sd = sigma_noise)

```

## Calculate survival probability based on parameters above

Based on the parameters set above, we calculate the probability of survival using both the linear and quadratic form. So far each seedling, there are two separate survival probabilities - one based on survival being a linear function of NCDD and one based on survival being a non-linear, quadratic function of NCDD.

```{r Simulate survival probability based on parameters above, message=FALSE}

# First calculate effect on logit scale
  dat.sim$surv.logit <- with(dat.sim, # using 'with' function here to condense code
                                   c(u_intercept + 
                                     spp.effect + 
                                     census.effect +
                                     plot.effect +
                                     site.effect +
                                     noise))

  # Add in NDD effects
   dat.sim$surv.logit.linear =  with(dat.sim, surv.logit + 
                                   NDD.effect * con_dens_scaled)
   
    dat.sim$surv.logit.quadratic =  with(dat.sim, surv.logit + 
                                   NDD.effect * con_dens_scaled +
                                   NDD2.effect * con_dens_scaled^2 )

  # Convert from logit scale to probability of survival 
   dat.sim$surv.prob.linear <- plogis(dat.sim$surv.logit.linear)
   dat.sim$surv.prob.quadratic <- plogis(dat.sim$surv.logit.quadratic)

```

## Determine survival status

To determine whether each seedling lived or died across the census interval, we draw from a binomial distribution where 1 = alive, 0 = dead, based on the calculated survival probability

```{r Determining if seedling is alive or dead}
# Determine if alive or dead
  dead.sim.linear <- foreach(i = 1:nrow(dat.sim), .combine = "c") %dopar% 
                rbinom(n = 1, size = 1, prob = dat.sim$surv.prob.linear[i])

  dead.sim.quadratic <- foreach(i = 1:nrow(dat.sim), .combine = "c") %dopar% 
                rbinom(n = 1, size = 1, prob = dat.sim$surv.prob.quadratic[i])

  # Save in main dataframe
  dat.sim$status.linear <- dead.sim.linear
  dat.sim$status.quadratic <- dead.sim.quadratic


  # Summary stats - number of alive and dead
  cat("Survival rate (linear): ", round(sum(dat.sim$status.linear == 1)/nrow(dat.sim), 2)*100, "%")
  cat("Survival rate (quadratic): ", round(sum(dat.sim$status.quadratic == 1)/nrow(dat.sim), 2)*100, "%")

```

## Fit models to linear survival data

Here, we will fit a set of 3 models to both the linear survival data

-   glm.noquad = GLMER with no quadratic term for NDD
-   glm.quad = GLMER with a quadratic term
-   gam.fit = GAM with a smoothing term for NDD

The results of the model summaries are shown in the tabs below.

::: panel-tabset
## GLM - Linear

```{r}

# Fit to linear survival data
glm.linear.noquad <- glmer(status.linear ~ con_dens_scaled + (1 | spp) + (1 | plot) + (1 | census),
             family = binomial(link = "logit"),
             control=glmerControl(optimizer="bobyqa"),
             data = dat.sim)

summary(glm.linear.noquad)

```

## GLM - Quadratic

```{r}
glm.linear.quad <- glmer(status.linear ~ con_dens_scaled + I(con_dens_scaled^2) + (1 | spp) + (1 | plot) + (1 | census),
             family = binomial(link = "logit"),
             control=glmerControl(optimizer="bobyqa"),
             data = dat.sim)

summary(glm.linear.quad)

```

## GAM

```{r}
 # Need to convert random effects to factors first or will get error when fitting model
dat.sim$spp <- factor(dat.sim$spp)
dat.sim$plot <- factor(dat.sim$plot)
dat.sim$census <- factor(dat.sim$census)

# Fit Gam
gam.linear <- gam(status.linear ~  
                  s(con_dens_scaled) + 
                  s(spp, bs = "re") + 
                  s(plot, bs = "re") + 
                  s(census, bs = "re"),
                  family = binomial(link = "logit"),
                  method = "ML", # use this to be able to get confidence intervals
                  data = dat.sim)

summary(gam.linear)
```
:::

## Fit models to quadratic survival data

Here, we fit the same 3 model forms to the quadratic survival data

::: panel-tabset
## GLM - Linear

```{r}

# Fit to quadratic survival data
glm.quadratic.noquad <- glmer(status.quadratic ~ con_dens_scaled + (1 | spp) + (1 | plot) + (1 | census),
             family = binomial(link = "logit"),
             control=glmerControl(optimizer="bobyqa"),
             data = dat.sim)

summary(glm.quadratic.noquad)

```

## GLM - Quadratic

```{r}
glm.quadratic.quad <- glmer(status.quadratic ~ con_dens_scaled + I(con_dens_scaled^2) + (1 | spp) + (1 | plot) + (1 | census),
             family = binomial(link = "logit"),
             control=glmerControl(optimizer="bobyqa"),
             data = dat.sim)

summary(glm.quadratic.quad)

```

## GAM

```{r}
# Fit Gam
gam.quadratic <- gam(status.quadratic ~  
                  s(con_dens_scaled) + 
                  s(spp, bs = "re") + 
                  s(plot, bs = "re") + 
                  s(census, bs = "re"),
                  family = binomial(link = "logit"),
                  method = "ML", # use this to be able to get confidence intervals
                  data = dat.sim)

summary(gam.quadratic)
```
:::

## Plotting predicted in survival probability

For each fit model, we plot the predicted change in survival probability based on changes in conspecific density. We also plot the known 'truth' based on the simulation parameters.

::: panel-tabset
### Linear survival data

```{r plot surv prob}
 # Generate prediction dataframe
  pred <- expand_grid(con_dens_scaled = dat.sim$con_dens_scaled,
                      total_dens_scaled = 0)

  # Add in truth
  pred$truth.linear <- plogis(u_intercept + 
                       pred$con_dens_scaled * beta_NDD)

  # Predict from models
  pred$pred.glm.linear.noquad <- predict(glm.linear.noquad, 
                                         newdata = pred, 
                                         type = "response",
                                            re.form = ~0)
  pred$pred.glm.linear.quad <- predict(glm.linear.quad, 
                                       newdata = pred, 
                                       type = "response",
                                       re.form = ~0)
  pred$pred.gam <- plogis(predict(gam.linear, newdata = pred,
                                  terms = c("s(con_dens_scaled)", "(Intercept)"),
                                  newdata.guaranteed=TRUE))
  
  # Reformat data to long
  pred <- pred %>%
    pivot_longer(-c(con_dens_scaled, total_dens_scaled),
                 names_to = "model_type", values_to = "pred" )

  # Make plot
  ggplot(pred, aes(con_dens_scaled, pred, col = model_type)) +
    geom_line(lwd = 1.5, alpha = 0.75) +
    scale_color_brewer(palette="Spectral") +
    labs(x = "con_dens_scaled", y = "Predicted survival probability", title = "Survival probabilty by conspecific density - community wide") +
    theme_bw(12)
  
```

### Quadratic survival data

```{r plot surv prob quadratic}
 # Generate prediction dataframe
  pred <- expand_grid(con_dens_scaled = dat.sim$con_dens_scaled,
                      total_dens_scaled = 0) 

  # Add in truth
  pred$truth.quadratic <- plogis(u_intercept + 
                       pred$con_dens_scaled * beta_NDD + 
                       pred$con_dens_scaled^2 * beta_NDD2)

  # Predict from models
  pred$pred.glm.quadratic.noquad <- predict(glm.quadratic.noquad, 
                                            newdata = pred, 
                                            type = "response",
                                            re.form = ~0)
  pred$pred.glm.quadratic.quad <- predict(glm.quadratic.quad, 
                                          newdata = pred, 
                                          type = "response",
                                          re.form = ~0)
  pred$pred.gam <- plogis(predict(gam.quadratic, newdata = pred,
                                  terms = c("s(con_dens_scaled)", "(Intercept)"),
                                  newdata.guaranteed=TRUE))
  
  # Reformat data to long
  pred <- pred %>%
    pivot_longer(-c(con_dens_scaled, total_dens_scaled),
                 names_to = "model_type", values_to = "pred" )

  # Make plot
  ggplot(pred, aes(con_dens_scaled, pred, col = model_type)) +
    geom_line(lwd = 1.5, alpha = 0.75) +
    scale_color_brewer(palette="Spectral") +
    labs(x = "con_dens_scaled", y = "Predicted survival probability", title = "Survival probabilty by conspecific density - community wide") +
    theme_bw(12)
  
```
:::

## Model diagnostics 

Here, we run some model diagnostics using the ['DHARMa' package](https://florianhartig.github.io/DHARMa/), which 'uses a simulation-based approach to create readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed models.' We can use these diagnostics to identify any model mispecifications.

```{r, warning=FALSE, message=FALSE}

## Plotting residuals vs. covariates using DHARMa

  # GLMER - linear
  glm.linear.noquad.sim.resids <- DHARMa::simulateResiduals(fittedModel = glm.linear.noquad, plot = FALSE)
  glm.quadratic.noquad.sim.resids <- DHARMa::simulateResiduals(fittedModel = glm.quadratic.noquad, plot = FALSE)

  # GLMER - nonlinear
  glm.linear.quad.sim.resids <- DHARMa::simulateResiduals(fittedModel = glm.linear.quad, plot = FALSE)
  glm.quadratic.quad.sim.resids <- DHARMa::simulateResiduals(fittedModel = glm.quadratic.quad, plot = FALSE)

  # Gam
  gam.linear.resids <- DHARMa::simulateResiduals(fittedModel = gam.linear, plot = FALSE)
  gam.quadratic.resids <- DHARMa::simulateResiduals(fittedModel = gam.quadratic, plot = FALSE)

```

### Linear survival data

Here, we show plots for residuals plotted against conspecific density. We see no issues in the residuals with the linear survival data, as expected.

::: panel-tabset
## GLM - Linear

```{r}


  # GLMER - linear
  plotResiduals(glm.linear.noquad.sim.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```

## GLM - Quadratic

```{r}

  # GLMER - nonlinear
  plotResiduals(glm.linear.quad.sim.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```

## GAM

```{r}
 
  # Gam
  plotResiduals(gam.linear.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```
:::

### Quadratic survival data

When we create residual plots plotted against conspecific density for the quadratic survival data, we see that the linear GLM has issues with residuals, while the quadratic GLM and GAM do not have issues.

::: panel-tabset
## GLM - Linear

```{r}
  # GLMER - linear
  plotResiduals(glm.quadratic.noquad.sim.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```

## GLM - Quadratic

```{r}
  # GLMER - nonlinear
  plotResiduals(glm.quadratic.quad.sim.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```

## GAM

```{r}

  # Gam
  plotResiduals(gam.quadratic.resids, form = dat.sim$con_dens_scaled, quantreg = TRUE)

```
:::

## Model comparisons with AIC and other metrics

Using AIC scores, we see that the GAM models consistently outperform the GLMER models for both the linear and quadratic survival data.

### Linear survival data

```{r model comparisons with AIC linear, warning=FALSE}

  comp <- compare_performance(glm.linear.noquad,
                              glm.linear.quad,
                              gam.linear)
  knitr::kable(comp %>% arrange(desc(AICc_wt)) %>% 
                 select(Name, Model, AICc, AICc_wt))
  
```

### Quadratic survival data

```{r model comparisons with AIC quadratic, warning=FALSE}

  comp <- compare_performance(glm.quadratic.noquad,
                              glm.quadratic.quad,
                              gam.quadratic)
  knitr::kable(comp %>% arrange(desc(AICc_wt)) %>% 
                 select(Name, Model, AICc, AICc_wt))
  
```
