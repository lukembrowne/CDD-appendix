---
output: html_document
editor_options: 
  chunk_output_type: console
execute: 
  cache: false
---

# Calculating Marginal Effects

## Overview

In this section we aim to:

-   Fit Gam models for each species

-   Calculate the Average Marginal Effect (AME)

-   Calculate the Relative Average Marginal Effect (RAME) - this is used for the meta-analyses, which is covered in the next section of the tutorial.

We use a subset of the BCI seedling data of only 30 species. This analysis is for demonstration purposes only, and biological conclusions should not be made about the results, given this is only a small subset of the data.

### Next steps in this tutorial:

-   Calculation of AME and RAME using "marginaleffects" function suitable for seedlings as marginaleffects delta is defined as +1 from the co-variate of interest. Functionalities are explained here: [https://vincentarelbundock.github.io/marginaleffects/articles/slopes.html](https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fvincentarelbundock.github.io%2Fmarginaleffects%2Farticles%2Fslopes.html&data=05%7C01%7Cnohemi.huanca%40yale.edu%7C0e19aa85c1d14217984f08db66882009%7Cdd8cbebb21394df8b4114e3e87abeb5c%7C0%7C0%7C638216507082081231%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=hWSNNHhPLg4cMM6rjRJdvEmgmdTujV66n8Ym%2FKqi9yQ%3D&reserved=0 "Original URL: https://vincentarelbundock.github.io/marginaleffects/articles/slopes.html. Click or tap if you trust this link.")

::: callout-note
Note: The code is adapted from the [latitudinalCNDD repository](https://github.com/LisaHuelsmann/latitudinalCNDD/tree/main/code) by [Lisa HÃ¼elsmann](https://demographicecology.com/).
:::

## Load libraries and data

```{r, message=FALSE}

# Load libraries
library(readr)
library(skimr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(parallel)
library(pbapply) # Adds progress bar to apply functions
library(here)
library(spatstat.geom)
library(mgcv) # For fitting gams
library(lubridate) # For calculating census intervals
library(broom) # For processing fit models
library(gratia)
library(boot)
library(mgcViz)
library(MASS)
```

This data is a subset from the BCI seedling data

```{r, message=FALSE}
data_BCI <- read_csv("./data/BCI_seedling data_30 species_2023_05_18.csv")
# make sure variables are taken as factor
data_BCI$census <- factor(data_BCI$census)
data_BCI$spp <- factor(data_BCI$spp)
data_BCI$plot <- factor(data_BCI$plot)
data_BCI$s_height=data_BCI$height.last.census
data_BCI$interval=as.numeric(data_BCI$time.since.last.census)
```

Let's take a quick look at the data set we'll be working with:

```{r}
  
# Exploring data 
skim(data_BCI)
  # visualize 
  ggplot(data_BCI, aes(x = con_dens)) +
  geom_histogram(binwidth = 1, color = "black", fill = "steelblue2") +
  labs(x = "Conspecific density", y = "Count", title = "Conspecific densities") + 
  theme_bw(12)
   
```

## Handling rare species

We classified the species as rare if they have fewer than four unique con-specific density values. We will create a data frame called "nsp" that describe all the species and its classification as rare or not rare.

```{r, message=FALSE, warning=FALSE}

nval = 4  ## this is the number of unique conspecific values
minrange = 1    # minimum range for conspecific density

data_BCI %>% 
  group_by(spp) %>% 
  summarise(
            range_con_dens = max(con_dens) - min(con_dens),
            max_con_dens = max(con_dens),
            unique_con_dens = length(unique(con_dens)),
            unique_total_dens = length(unique(total_dens)),
            unique_height = length(unique(height.last.census))
  ) %>% 
  
  
  mutate(issue_nval = unique_con_dens < nval,              # less than nval unique values in consp densities
  issue_range = range_con_dens < minrange,                    # range should at least be equal to minrange
  trymodel = !(issue_nval|issue_range),    
  rare = !trymodel                                          # preliminary assignment of rare species
  ) -> nsp

#From our specifific data set 9 species out of 30 were assigned as rare. 
```

## Function for fitting models

Here we defined the formula (co-variates) for the gam models and specified the smooth term in the model formula. If a k value is greater than the number of unique values in the corresponding variable, it is reduced to be two less than the number of unique values. We also check for model convergence and warnings.

```{r, message=FALSE, warning=FALSE}

model_fit = function(data, speciesinfo, reduced = F) {
  
  # create new factor with correct factor levels per species 
  data$census = factor(data$census)
  
  
  # create model formula
  term_c = ifelse(length(unique(data$census)) > 1, "+ s(census, bs = 're')", "") 
  #term_p = "+ s(plot, bs = 're')"
  
  if (reduced) {
    form =  as.formula(paste0("status ~ s(s_height, k = k1) + s(total_dens, k = k2)"
                              , term_c)) # reduced model #,term_p
  } else {
    form =  as.formula(paste0("status ~ s(s_height, k = k1) + s(total_dens, k = k2)  + s(con_dens, k = k3)" 
                              , term_c)) # full model #, term_p
  }
  
  # Choose penalty
  # set to default k=10 
  k1 = k2 = k3 = 10
  if (k1 > speciesinfo$unique_height) k1 = speciesinfo$unique_height - 2
  if (k2 > speciesinfo$unique_total_dens) k2 = speciesinfo$unique_total_dens - 2
  if (k3 > speciesinfo$unique_con_dens) k3 = speciesinfo$unique_con_dens - 2
  
  
  # Fit model
  mod = try(gam(form
                , family = binomial(link=cloglog)
                , offset = log(interval)
                , data = data
                , method = "REML"
  ) , silent = T
  )
  
  return(mod)
  
}

# check model run

model_convergence = function(model) {
  
  # gam not available
  if (!any(class(model)=="gam")) {
    print(paste(spp, "gam failed"))
  } else {
    
    # gam not converged
    if (!model$converged) {
      print(paste(spp, "no convergence"))
    } else {
      
    
# Explore warning "glm.fit: fitted probabilities numerically 0 or 1 occurred (complete separation)"
      eps <- 10 * .Machine$double.eps
      glm0.resids <- augment(x = model) %>%
        mutate(p = 1 / (1 + exp(-.fitted)),
               warning = p > 1-eps,
               influence = order(.hat, decreasing = T))
      infl_limit = round(nrow(glm0.resids)/10, 0)
      # check if none of the warnings is among the 10% most influential observations, than it is okay..
      num = any(glm0.resids$warning & glm0.resids$influence < infl_limit)
      
      # complete separation
      if (num) {
        print(paste(spp, "complete separation is likely"))
      } else {
        
        # missing Vc
        if (is.null(model$Vc)) {
          print(paste(spp, "Vc not available"))
        } else {
        
        # successful model
        return(model)
        }
      }
    }
  }
}

```

## Fit models each species that is not rare

```{r, message=FALSE, warning=FALSE}

res_mod = list()      # main model fits
res_red_mod = list()  # reduced model fits for Pseudo R2


# Fit models for individual species
for (spp in nsp$spp[nsp$trymodel]) {
  
  # select data for individual species
  dat_sp = data_BCI[data_BCI$spp == spp, ]
  
  # model fit and reduced fit for Pseudo R2
  mod = model_fit(data = dat_sp, speciesinfo = nsp[nsp$spp == spp, ])
  mod_red = model_fit(data = dat_sp, speciesinfo = nsp[nsp$spp == spp, ], reduced = T)
  
  # check model success
  res = model_convergence(model = mod)
  res_red = model_convergence(model = mod_red)
  
  # save result
  if (is.character(res)) {
    nsp$rare[nsp$spp == spp] = T  
  } else {
    res_mod[[spp]] = res
    res_red_mod[[spp]] = res_red
  }
}

```

## Fit models for all species ( and include rare species)

Here we fit the model for all species. Rare species are treated as group since there is not sufficient data to be treated independently.

```{r, message=FALSE, warning=FALSE}

# overview rare versus rare and no convergence
table(rare = nsp$rare, trymodel = nsp$trymodel) # We have 9 species here that are considered rare

# Convert spp to character
data_BCI$spp <- as.character(data_BCI$spp)

# Create a vector of rare species
rare_species <- nsp$spp[nsp$rare == TRUE]

# Replace spp values to "rare_seedling" where nsp$rare is TRUE
data_BCI2 <- data_BCI %>% 
  mutate(spp = ifelse(spp %in% rare_species, "rare_seedling", spp))

# Now calculate the attributes for each spp including the "rare_seedling"
data_BCI2 %>%
  group_by(spp) %>%
  summarise(
    range_con_dens = max(con_dens, na.rm = TRUE) - min(con_dens, na.rm = TRUE),
    max_con_dens = max(con_dens, na.rm = TRUE),
    unique_con_dens = length(unique(con_dens)),
    unique_total_dens = length(unique(total_dens)),
    unique_height = length(unique(height.last.census))
  ) %>%
  mutate(
    issue_nval = unique_con_dens < nval,                  # less than nval unique values in consp densities
    issue_range = range_con_dens < minrange,              # range should at least be equal to minrange
    trymodel = !(issue_nval | issue_range),               
    rare = !trymodel                                      # preliminary assignment of rare species
  ) -> nsp_rare



# Fit models for all individual species included the rare group species
  
  for(spp in nsp_rare$spp[nsp_rare$trymodel]) {
  
  # select data for individual species
  dat_sp = data_BCI2[data_BCI2$spp == spp, ]
  
  # model fit and reduced fit for Pseudo R2
  mod = model_fit(data = dat_sp, speciesinfo = nsp_rare[nsp_rare$spp == spp, ])
  mod_red = model_fit(data = dat_sp, speciesinfo = nsp_rare[nsp_rare$spp == spp, ], reduced = T)
  
  # check model success
  res = model_convergence(model = mod)
  res_red = model_convergence(model = mod_red)
  
  # save result
  if (is.character(res)) {
    nsp$rare[nsp$spp == spp] = T  
  } else {
    res_mod[[spp]] = res
    res_red_mod[[spp]] = res_red
  }
}

```

## Summarize model fits

Regression table via broom::tidy()

```{r}
coefs = lapply(res_mod, broom::tidy)
coefs = Map(cbind, coefs, sp = names(coefs))
coefs = do.call(rbind, coefs)
```

Model summary via broom::glance()

```{r}
# df logLik AIC BIC deviance df.residuals nobs 
sums = lapply(res_mod, broom::glance)
sums = Map(cbind, sums, sp = names(sums))
sums = do.call(rbind, sums)
head(sums)

# AUC
aucs = lapply(res_mod, function(x) {
  roc <- performance::performance_roc(x, new_data = x$model)
  bayestestR::area_under_curve(roc$Spec, roc$Sens)
})
sums$AUC = unlist(aucs)


# Pseudo R2
sums$pseudoR2 = 1 - (unlist(lapply(res_mod, function(x) x$deviance)) / unlist(lapply(res_red_mod, function(x) x$deviance)))
```

## AMEs Absolute and Relative

AMEs relative are used to compare CDD across sites, plots, or any other unit of interest with a meta-analyses approach while absolute AMEs are reported as they are commonly used in other studies.

For AMEs we need the file "res_model" that have all the models results.

### Settings for AMEs

```{r}

#### chose predictors for local density
  
predictors <- c(con_dens = "con_dens", 
                total_dens = "total_dens")

# change in conspecific density for AME calculations----

additive=1     #One more neighbor or --> pi*((dbh_neighbor/1000)/2)^2 *
                                        #dec_fun(decay_con,dist_neighbor, decay_type) 
  
# different change settings for con-specific densities

interval = 1

change = list(equilibrium = data.frame(con_dens = "paste('+', additive)")
              , invasion = data.frame(con_dens = "c(0, additive)")
              , iqr = data.frame(con_dens = "c(q1, q3)")
              )
iter = 500

```

### Functions to calculate AMEs manually

This section defines two functions. setstep and get_AME. Get_AME is the function calculates the Average Marginal Effects (AMEs) for a given term in a model. The function first creates two copies of the data, **`d0`** and **`d1`**, and adjusts the term of interest based on the **`change`** argument. It then calculates the predictions for the two data sets and computes the marginal effects.

```{r}

# set step on x for numerical derivative
setstep = function(x) {
  eps = .Machine$double.eps
  x + (max(abs(x), 1, na.rm = TRUE) * sqrt(eps)) - x
}


# Average marginal effects ------------------------------------------------

get_AME = function(mod, data, term
                   , change = NULL
                   , at = NULL
                   , offset = 1
                   , relative = F
                   , iterations = 1000
                   , seed = 10
                   , samples = F) {
  
  #  Creating two copies of the data frames one of which will shift in term of interest:
  d0 = d1 = data
  
  # Adjusting the term of interests with the different options of change
  
  # if change is NULL, use numerical derivative
  if (is.null(change)) {
    
    d0[[term]] = d0[[term]] - setstep(d0[[term]])
    d1[[term]] = d1[[term]] + setstep(d1[[term]])
    
  } 
  
  # if change includes "+", use explicit additive change
  if (grepl("\\+", paste(change, collapse = "_"))) {
    
    d1[[term]] = d1[[term]] + as.numeric(gsub("\\+", "", change))
    
  } 
  
  # if change has two values, use explicit change
  if (length(change) == 2) {
    
    d0[[term]] = as.numeric(change[1])
    d1[[term]] = as.numeric(change[2])
    
  }
  
  # Fix at values: (allows the function to calculate the marginal effects at the specified values)
  if (!is.null(at)) {
    for (i in names(at))
      d0[[i]] = at[[i]]
      d1[[i]] = at[[i]]
  }
  
  # Matrices for prediction, map coefs to fitted curves
  Xp0 <- predict(mod, newdata = d0, type="lpmatrix")
  Xp1 <- predict(mod, newdata = d1, type="lpmatrix")
  
  # Model settings
  ilink <- family(mod)$linkinv
  beta <- coef(mod)
  vc <- mod$Vc # covariance matrix 
  

  # marginal effects
  pred0   <- 1 - (1-ilink(Xp0 %*% beta))^offset
  pred1   <- 1 - (1-ilink(Xp1 %*% beta))^offset
  ME <- (pred1-pred0)
  
  # if change is NULL, use numerical derivative
  if (is.null(change)) {
    ME <- ME/(d1[[term]] - d0[[term]])
  } 

  
  # convert to relative if requested
  if (relative == T) ME = ME/pred0
  
  # average marginal effect
  AME = mean(ME)
  
  
  # generate AME samples for calculating uncertainty in the AME estimates
  
  # variance of average marginal effect via "posterior" simulation
  # simulate from multivariate normal using model beta means and covariance matrix
  if (!is.null(seed)) set.seed(seed)
  coefmat = mvrnorm(n = iterations
                    , mu = beta
                    , Sigma = vc)
  
  # estimate AME from each simulated coefficient vector
  AMEs = apply(coefmat, 1, function(coefrow) {
    
    # marginal effects
    pred0   <- 1 - (1-ilink(Xp0 %*% coefrow))^offset
    pred1   <- 1 - (1-ilink(Xp1 %*% coefrow))^offset
    ME <- (pred1-pred0)
    
    # if change is NULL, use numerical derivative
    if (is.null(change)) {
      ME <- ME/(d1[[term]] - d0[[term]])
    } 
    
    # convert to relative if requested
    if (relative == T) ME = ME/pred0
    
    # average marginal effect
    AME = mean(ME)
    return(AME)
  })
  
  # Combine results
  if (!samples) {
    res = data.frame(term
                     , estimate = AME
                     , std.error = sqrt(var(AMEs))  
                     , estimate.sim = mean(AMEs)    
                     , offset
                     , change.value = paste(change, collapse = "_"))
    return(res) 
    
  } else {
    
    res_sums = data.frame(term
                     , estimate = AME
                     , std.error = sqrt(var(AMEs)) 
                     , offset
                     , change.value = paste(change, collapse = "_"))
    
    res_samples = data.frame(term
                             , estimate = AMEs
                             , MLE = AME
                             , offset
                             , change.value = paste(change, collapse = "_"))
    res = list(res_sums, res_samples)
    return(res)  
    
  }
}

```

### Calculating Absolute Average Marginal Effect (AMEs)

At the end of this code, the **`AME`** data frame contains the AME estimates for the predictor and each type of change, and the **`AMEsamples`** data frame contains the AME samples for each predictor and type of change

```{r}
# Absolute AMEs -----------------------------------------------------------

# Calculate absolute AMEs based on manual function get_AME
AME = data.frame()
AMEsamples = data.frame()
for (i in names(predictors)[grepl("con_", names(predictors))]) { 
  for (j in names(change)) {
    temp = lapply(res_mod, function(x){
      if (j == "iqr") {
        q1 = quantile(x$model$con_dens, probs = 0.25)
        q3 = quantile(x$model$con_dens, probs = 0.75)
      }
      get_AME(x
              , data = x$model
              , offset = interval
              , term = i
              , change = eval(parse(text = change[[j]][,i]))
              , iterations = iter
              , samples = T
      )
    }
    )
    
    # AME
    tempAME = lapply(temp, function(x) x[[1]])
    tempAME = Map(cbind, tempAME, change = j, sp = names(tempAME))
    tempAME = do.call(rbind, tempAME)
    AME = rbind(AME, tempAME)
    
    # AME samples
    tempSamples = lapply(temp, function(x) x[[2]])
    tempSamples = Map(cbind, tempSamples, change = j, sp = names(tempSamples), iter = iter)
    tempSamples = do.call(rbind, tempSamples)
    AMEsamples = rbind(AMEsamples, tempSamples)
  }
}
head(AME)
```

### Calculating Relative Average Marginal Effect (rAMEs)

At the end of this code, the **`rAME`** data frame contains the rAME estimates for the predictor and each type of change, and the **`rAMEsamples`** data frame contains the rAME samples for each predictor and type of change. The type of change used For the next chapter, we will be using the rAME "equilibrium" change type, where the changed is +1 from current con_specific density.

```{r}
# Relative AMEs -----------------------------------------------------------


# Calculate relative AMEs based on manual function get_AME
rAME = data.frame()
rAMEsamples = data.frame()
for (i in names(predictors)[grepl("con_", names(predictors))]) { # for all predictors
  for (j in names(change)) {
    temp = lapply(res_mod, function(x){
      if (j == "iqr") {
        q1 = quantile(x$model$con_dens, probs = 0.25)
        q3 = quantile(x$model$con_dens, probs = 0.75)
      }
      get_AME(x
              , data = x$model
              , offset = interval
              , term = i
              , change = eval(parse(text = change[[j]][, i]))
              , iterations = iter
              , relative = T
              , samples = T
      )
    }
    )
    
    # rAME
    tempAME = lapply(temp, function(x) x[[1]])
    tempAME = Map(cbind, tempAME, change = j, sp = names(tempAME))
    tempAME = do.call(rbind, tempAME)
    rAME = rbind(rAME, tempAME)
    
    # rAME samples
    tempSamples = lapply(temp, function(x) x[[2]])
    tempSamples = Map(cbind, tempSamples, change = j, sp = names(tempSamples), iter = iter)
    tempSamples = do.call(rbind, tempSamples)
    rAMEsamples = rbind(rAMEsamples, tempSamples)
  }
}
head(rAME)
```

## Plotting and saving results

```{r}
# plot splines in pdf -----------------------------------------------------

# Set the PDF file name
pdf_file <- "mortality.pdf" # save as pdf all the species figures

for (i in 1:length(res_mod))  {
  
  # with gamViz
  vizmod <- getViz(res_mod[[i]], post = T, unconditional = T)
  pl = plot(vizmod, nsim = 20, allTerms = T) + 
    l_ciLine() + l_fitLine() + l_simLine() + 
    l_ciBar() + l_fitPoints(size = 1) + 
    l_rug() + 
    labs(title = names(res_mod)[i]) 

  # Print the plot to the R console only for the first 3 species
  if (i <= 3) {
    print(pl, pages = 1)
  }
  
  # Save the plot to the PDF
  pdf(pdf_file)
  print(pl, pages = 1)
  dev.off()
}


# Save results ------------------------------------------------------------


save(list = c("AME", "AMEsamples", "rAME", "rAMEsamples", "nsp", "coefs", "sums") # "nsp_rare"
     , file = paste0( "./data/mortality.Rdata"))
# load("mortality.Rdata")
write.csv(AME, "AME.csv")
write.csv(rAME, "rAME.csv")

```
